{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextCleaner(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return X.apply(self.clean_text)\n",
    "\n",
    "    @staticmethod\n",
    "    def clean_text(text):\n",
    "        if pd.isna(text):\n",
    "            return ''\n",
    "        text = str(text).lower()\n",
    "        text = re.sub(r'[^\\w\\s]', ' ', text)  # Remove punctuation\n",
    "        text = re.sub(r'\\d+', ' ', text)      # Remove digits\n",
    "        text = ' '.join(text.split())        # Normalize whitespace\n",
    "        return text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading data...\")\n",
    "train_df = pd.read_csv('../data/train.csv')\n",
    "test_df = pd.read_csv('../data/test.csv')\n",
    "combined_df = pd.concat([train_df, test_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing rare classes...\n",
      "Instances removed: 8832\n"
     ]
    }
   ],
   "source": [
    "print(\"Removing rare classes...\")\n",
    "min_instances = 5\n",
    "category_counts = combined_df['category'].value_counts()\n",
    "sub_category_counts = combined_df['sub_category'].value_counts()\n",
    "\n",
    "valid_categories = category_counts[category_counts >= min_instances].index\n",
    "valid_sub_categories = sub_category_counts[sub_category_counts >= min_instances].index\n",
    "\n",
    "filtered_df = combined_df[\n",
    "    (combined_df['category'].isin(valid_categories)) &\n",
    "    (combined_df['sub_category'].isin(valid_sub_categories))\n",
    "].copy()\n",
    "\n",
    "print(\"Instances removed:\", len(combined_df) - len(filtered_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_svm_pipeline():\n",
    "    # Create an SVM classifier\n",
    "    svm_classifier = SVC(probability=True, random_state=42) # probability=True for compatibility with MultiOutputClassifier if needed, though not strictly necessary for SVC itself\n",
    "\n",
    "    pipeline = Pipeline([\n",
    "        ('cleaner', TextCleaner()),  # Custom text cleaning step\n",
    "        ('tfidf', TfidfVectorizer()),  # TF-IDF vectorization\n",
    "        ('clf', MultiOutputClassifier(svm_classifier))  # Multi-output SVM classifier\n",
    "    ])\n",
    "\n",
    "    return pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = filtered_df['crimeaditionalinfo']\n",
    "y = filtered_df[['category', 'sub_category']]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the SVM model...\n"
     ]
    }
   ],
   "source": [
    "print(\"Training the SVM model...\")\n",
    "pipeline = create_svm_pipeline()\n",
    "pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Predicting...\")\n",
    "y_pred = pipeline.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_category, y_pred_sub_category = y_pred[:, 0], y_pred[:, 1]\n",
    "y_test_category, y_test_sub_category = y_test['category'], y_test['sub_category']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(y_true, y_pred, label):\n",
    "    return {\n",
    "        \"Accuracy\": accuracy_score(y_true, y_pred),\n",
    "        \"Precision\": precision_score(y_true, y_pred, average=\"macro\", zero_division=0),\n",
    "        \"Recall\": recall_score(y_true, y_pred, average=\"macro\", zero_division=0),\n",
    "        \"F1 Score\": f1_score(y_true, y_pred, average=\"macro\", zero_division=0),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_metrics = calculate_metrics(y_test_category, y_pred_category, \"Category\")\n",
    "sub_category_metrics = calculate_metrics(y_test_sub_category, y_pred_sub_category, \"Sub-category\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nCategory Metrics:\")\n",
    "for metric, value in category_metrics.items():\n",
    "    print(f\"{metric}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nSub-category Metrics:\")\n",
    "for metric, value in sub_category_metrics.items():\n",
    "    print(f\"{metric}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nCategory Classification Report:\")\n",
    "print(classification_report(y_test_category, y_pred_category, zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nSub-category Classification Report:\")\n",
    "print(classification_report(y_test_sub_category, y_pred_sub_category, zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(y_true, y_pred, labels, title):\n",
    "    cm = confusion_matrix(y_true, y_pred, labels=labels)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=labels, yticklabels=labels)\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('Actual')\n",
    "    plt.title(title)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Plotting confusion matrices...\")\n",
    "plot_confusion_matrix(y_test_category, y_pred_category, labels=y['category'].unique(), title=\"Confusion Matrix for 'Category'\")\n",
    "plot_confusion_matrix(y_test_sub_category, y_pred_sub_category, labels=y['sub_category'].unique(), title=\"Confusion Matrix for 'Sub-category'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "\n",
    "print(\"=== PERFORMANCE METRICS ===\")\n",
    "\n",
    "sample_text = X_test.iloc[0:1]\n",
    "start_time = time.time()\n",
    "_ = pipeline.predict(sample_text)\n",
    "latency = (time.time() - start_time) * 1000  # Convert to milliseconds\n",
    "print(f\"Latency: {latency:.2f} ms\")\n",
    "\n",
    "batch_sizes = [1, 10, 100, 1000]\n",
    "speeds = []\n",
    "\n",
    "for batch_size in batch_sizes:\n",
    "    if batch_size <= len(X_test):\n",
    "        batch = X_test.iloc[:batch_size]\n",
    "        start_time = time.time()\n",
    "        _ = pipeline.predict(batch)\n",
    "        elapsed = time.time() - start_time\n",
    "        speed = batch_size / elapsed\n",
    "        speeds.append(speed)\n",
    "        print(f\"Batch size {batch_size}: {speed:.1f} predictions/sec\")\n",
    "\n",
    "print(f\"\\nScalability Analysis:\")\n",
    "print(f\"Max throughput: {max(speeds):.1f} predictions/sec\")\n",
    "print(f\"Throughput efficiency: {(max(speeds)/speeds[0]):.1f}x improvement with batching\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
